{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# OctoAI\n",
    "# ! pip install langchain langchain-community faiss-cpu sentence-transformers octoai-sdk langchain-text-splitters lxml tiktoken python-dotenv 'arize-phoenix[evals]'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import octoai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OCTOAI_API_TOKEN = \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IjNkMjMzOTQ5In0.eyJzdWIiOiJkNTY1Y2Q3YS0zYmNjLTQzNDgtOGQxYy1mMGY0ZjY0ODkyYzciLCJ0eXBlIjoidXNlckFjY2Vzc1Rva2VuIiwidGVuYW50SWQiOiJkMzRmOGVkZC1kMzE1LTQ4NTktOTc0Zi03MjJiMzNlNDA5ZDIiLCJ1c2VySWQiOiJhZTMxM2ExZS1lYTI3LTRkOTItYjk5OS1iOTNlY2Q0YjQ3NTgiLCJhcHBsaWNhdGlvbklkIjoiYTkyNmZlYmQtMjFlYS00ODdiLTg1ZjUtMzQ5NDA5N2VjODMzIiwicm9sZXMiOlsiRkVUQ0gtUk9MRVMtQlktQVBJIl0sInBlcm1pc3Npb25zIjpbIkZFVENILVBFUk1JU1NJT05TLUJZLUFQSSJdLCJhdWQiOiIzZDIzMzk0OS1hMmZiLTRhYjAtYjdlYy00NmY2MjU1YzUxMGUiLCJpc3MiOiJodHRwczovL2lkZW50aXR5Lm9jdG8uYWkiLCJpYXQiOjE3MTk2Nzg3NTl9.m3RpRr3vLoGekWhvk1fXHlTBAg1fkkO2V2eMfXddjLf30taFXnAOLoJIWHsGLupliLVW3JL9_wxPRhL2cGpDH_1_PeWDUYxKk_ZY1RjL9s_yoJf7fGeEy9-VPbmvjfYXcQTa_sxE99GeqwaODud26e_O04Q9n2KiNSwdeeion6ki9ctpIbDXZ3Wit_ltumGY0axDRInfm_QHwvo92r4W-3g8jN4lskS7ZA7CT5LCRq7GzFs5E2HsZq-59RnVhxnray6nG5fyG3U67Ff0ZCTuRaDY2DqRDOgQw1zRqTYMoW8zeOfozRxlGygdRcRU3AxnUOGOi7yijetkE9I60H9qlg\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "files = os.listdir(\"../workout_data\")\n",
    "file_texts = []\n",
    "for file in files:\n",
    "    with open(f\"../workout_data/{file}\") as f:\n",
    "        file_text = f.read()\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=1024, chunk_overlap=128, \n",
    "    )\n",
    "    texts = text_splitter.split_text(file_text)\n",
    "    for i, chunked_text in enumerate(texts):\n",
    "        file_texts.append(Document(page_content=chunked_text, \n",
    "                metadata={\"doc_title\": file.split(\".\")[0], \"chunk_num\": i}))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "vector_store = FAISS.from_documents(\n",
    "    file_texts,\n",
    "    embedding=embeddings\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search the Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_community.llms.octoai_endpoint import OctoAIEndpoint\n",
    "llm = OctoAIEndpoint(\n",
    "        model=\"mixtral-8x7b-instruct\",\n",
    "        max_tokens=8192,\n",
    "        presence_penalty=0,\n",
    "        temperature=0,\n",
    "        top_p=0.9,\n",
    "        octoai_api_token=OCTOAI_API_TOKEN\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "retriever = vector_store.as_retriever()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template=\"\"\"You are a data analyst. You will be given unstructured data texts and figure out the schema. Return the schema. Be as general as possible so the schema can be used on most data input. Return the schema as Pydantic model code. If possible, create multiple tables and relations between them when you see fit. Only output a code segment. Do not provide Sample usage.\n",
    "Document: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "response = chain.invoke(\"Show me the table schema creation script\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T20:34:53.383930Z",
     "start_time": "2024-06-29T20:34:52.774155Z"
    }
   },
   "source": [
    "from octoai.client import OctoAI\n",
    "from clients.ollm import ChatCompletionResponseFormat\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Exercise(BaseModel):\n",
    "    name: str\n",
    "    sets: int\n",
    "    reps: int\n",
    "\n",
    "class Workout(BaseModel):\n",
    "    day: int\n",
    "    exercises: List[Exercise]\n",
    "\n",
    "class Program(BaseModel):\n",
    "    name: str\n",
    "    workouts: List[Workout]\n",
    "\n",
    "all_classes = [Exercise, Workout, Program]\n",
    "client = OctoAI(api_key=OCTOAI_API_TOKEN)\n",
    "completion = client.text_gen.create_chat_completion(\n",
    "    model=\"mistral-7b-instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant designed to output JSON\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I ran 10, 400 meter intervals today. Please record this.\",\n",
    "        },\n",
    "    ],\n",
    "    max_tokens=512,\n",
    "    presence_penalty=0,\n",
    "    temperature=0,\n",
    "    top_p=0.9,\n",
    "    response_format=ChatCompletionResponseFormat(\n",
    "        type=\"json_object\",\n",
    "        schema=Workout.model_json_schema(),\n",
    "    ),\n",
    ")\n",
    "print(completion.choices[0].message.content)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"answer\": \"10, 400 meter intervals were run today\"}\n"
     ]
    }
   ],
   "execution_count": 199
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcbs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
