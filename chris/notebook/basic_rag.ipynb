{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:24:49.124473Z",
     "start_time": "2024-06-29T19:24:49.121366Z"
    }
   },
   "source": [
    "# OctoAI\n",
    "# ! pip install langchain langchain-community faiss-cpu sentence-transformers octoai-sdk langchain-text-splitters lxml tiktoken python-dotenv 'arize-phoenix[evals]'"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:24:49.148084Z",
     "start_time": "2024-06-29T19:24:49.135636Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OCTOAI_API_TOKEN = \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IjNkMjMzOTQ5In0.eyJzdWIiOiJkNTY1Y2Q3YS0zYmNjLTQzNDgtOGQxYy1mMGY0ZjY0ODkyYzciLCJ0eXBlIjoidXNlckFjY2Vzc1Rva2VuIiwidGVuYW50SWQiOiJkMzRmOGVkZC1kMzE1LTQ4NTktOTc0Zi03MjJiMzNlNDA5ZDIiLCJ1c2VySWQiOiJhZTMxM2ExZS1lYTI3LTRkOTItYjk5OS1iOTNlY2Q0YjQ3NTgiLCJhcHBsaWNhdGlvbklkIjoiYTkyNmZlYmQtMjFlYS00ODdiLTg1ZjUtMzQ5NDA5N2VjODMzIiwicm9sZXMiOlsiRkVUQ0gtUk9MRVMtQlktQVBJIl0sInBlcm1pc3Npb25zIjpbIkZFVENILVBFUk1JU1NJT05TLUJZLUFQSSJdLCJhdWQiOiIzZDIzMzk0OS1hMmZiLTRhYjAtYjdlYy00NmY2MjU1YzUxMGUiLCJpc3MiOiJodHRwczovL2lkZW50aXR5Lm9jdG8uYWkiLCJpYXQiOjE3MTk2Nzg3NTl9.m3RpRr3vLoGekWhvk1fXHlTBAg1fkkO2V2eMfXddjLf30taFXnAOLoJIWHsGLupliLVW3JL9_wxPRhL2cGpDH_1_PeWDUYxKk_ZY1RjL9s_yoJf7fGeEy9-VPbmvjfYXcQTa_sxE99GeqwaODud26e_O04Q9n2KiNSwdeeion6ki9ctpIbDXZ3Wit_ltumGY0axDRInfm_QHwvo92r4W-3g8jN4lskS7ZA7CT5LCRq7GzFs5E2HsZq-59RnVhxnray6nG5fyG3U67Ff0ZCTuRaDY2DqRDOgQw1zRqTYMoW8zeOfozRxlGygdRcRU3AxnUOGOi7yijetkE9I60H9qlg\""
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:24:49.168199Z",
     "start_time": "2024-06-29T19:24:49.150874Z"
    }
   },
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:24:49.220770Z",
     "start_time": "2024-06-29T19:24:49.188500Z"
    }
   },
   "source": [
    "files = os.listdir(\"../workout_data\")\n",
    "file_texts = []\n",
    "for file in files:\n",
    "    with open(f\"../workout_data/{file}\") as f:\n",
    "        file_text = f.read()\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=1024, chunk_overlap=128, \n",
    "    )\n",
    "    texts = text_splitter.split_text(file_text)\n",
    "    for i, chunked_text in enumerate(texts):\n",
    "        file_texts.append(Document(page_content=chunked_text, \n",
    "                metadata={\"doc_title\": file.split(\".\")[0], \"chunk_num\": i}))"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:24:49.228051Z",
     "start_time": "2024-06-29T19:24:49.223758Z"
    }
   },
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:24:50.467316Z",
     "start_time": "2024-06-29T19:24:49.229947Z"
    }
   },
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:24:57.418580Z",
     "start_time": "2024-06-29T19:24:50.470509Z"
    }
   },
   "source": [
    "vector_store = FAISS.from_documents(\n",
    "    file_texts,\n",
    "    embedding=embeddings\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search the Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:24:57.584531Z",
     "start_time": "2024-06-29T19:24:57.421690Z"
    }
   },
   "source": [
    "from langchain_community.llms.octoai_endpoint import OctoAIEndpoint\n",
    "llm = OctoAIEndpoint(\n",
    "        model=\"mixtral-8x7b-instruct\",\n",
    "        max_tokens=8192,\n",
    "        presence_penalty=0,\n",
    "        temperature=0,\n",
    "        top_p=0.9,\n",
    "        octoai_api_token=OCTOAI_API_TOKEN\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmagorian/Storage/repos/hackathon-0629/.venv/lib/python3.10/site-packages/langchain_core/utils/utils.py:161: UserWarning: WARNING! model is not default parameter.\n",
      "                model was transferred to model_kwargs.\n",
      "                Please confirm that model is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:24:57.594168Z",
     "start_time": "2024-06-29T19:24:57.587530Z"
    }
   },
   "source": [
    "retriever = vector_store.as_retriever()"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:24:57.619088Z",
     "start_time": "2024-06-29T19:24:57.596705Z"
    }
   },
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template=\"\"\"You are a data analyst. You will be given unstructured data texts and figure out the schema. Return the schema. Be as general as possible so the schema can be used on most data input. Return the schema as Pydantic model code. If possible, create multiple tables and relations between them when you see fit.\n",
    "Document: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:24:57.634042Z",
     "start_time": "2024-06-29T19:24:57.623653Z"
    }
   },
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:25:03.041329Z",
     "start_time": "2024-06-29T19:24:57.636970Z"
    }
   },
   "source": "print(chain.invoke(\"Show me the table schema creation script\"))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ```python\n",
      "from typing import List\n",
      "from pydantic import BaseModel\n",
      "\n",
      "class Exercise(BaseModel):\n",
      "    name: str\n",
      "    sets: int\n",
      "    reps: int\n",
      "\n",
      "class Workout(BaseModel):\n",
      "    day: int\n",
      "    exercises: List[Exercise]\n",
      "\n",
      "class Program(BaseModel):\n",
      "    name: str\n",
      "    workouts: List[Workout]\n",
      "\n",
      "# Sample usage:\n",
      "program = Program(\n",
      "    name=\"Beginner Program\",\n",
      "    workouts=[\n",
      "        Workout(\n",
      "            day=1,\n",
      "            exercises=[\n",
      "                Exercise(name=\"barbell back squats\", sets=3, reps=5),\n",
      "                Exercise(name=\"flat barbell bench press\", sets=3, reps=5),\n",
      "                Exercise(name=\"seated cable rows\", sets=3, reps=6-8),\n",
      "                Exercise(name=\"seated dumbbell shoulder press\", sets=3, reps=6-8),\n",
      "                Exercise(name=\"cable rope triceps pushdowns\", sets=3, reps=8-10),\n",
      "                Exercise(name=\"lateral raises\", sets=3, reps=10-12),\n",
      "                Exercise(name=\"seated calf raises\", sets=3, reps=10-12),\n",
      "                Exercise(name=\"planks\", sets=3, reps=30-second holds),\n",
      "            ]\n",
      "        ),\n",
      "        # Add more workouts as needed\n",
      "    ]\n",
      ")\n",
      "```\n",
      "This Pydantic model defines a `Program` which contains a list of `Workout`s. Each `Workout` has a day number and a list of `Exercise`s. Each `Exercise` has a name, number of sets, and number of reps. This schema is flexible enough to accommodate the unstructured data provided.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T19:25:03.045865Z",
     "start_time": "2024-06-29T19:25:03.043106Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcbs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
