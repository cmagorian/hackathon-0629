{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1201300617.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install langchain langchain-community faiss-cpu sentence-transformers octoai-sdk langchain-text-splitters lxml tiktoken python-dotenv 'arize-phoenix[evals]'\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# OctoAI\n",
    "# ! pip install langchain langchain-community faiss-cpu sentence-transformers octoai-sdk langchain-text-splitters lxml tiktoken python-dotenv 'arize-phoenix[evals]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OCTOAI_API_TOKEN = \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IjNkMjMzOTQ5In0.eyJzdWIiOiJkNTY1Y2Q3YS0zYmNjLTQzNDgtOGQxYy1mMGY0ZjY0ODkyYzciLCJ0eXBlIjoidXNlckFjY2Vzc1Rva2VuIiwidGVuYW50SWQiOiJkMzRmOGVkZC1kMzE1LTQ4NTktOTc0Zi03MjJiMzNlNDA5ZDIiLCJ1c2VySWQiOiJhZTMxM2ExZS1lYTI3LTRkOTItYjk5OS1iOTNlY2Q0YjQ3NTgiLCJhcHBsaWNhdGlvbklkIjoiYTkyNmZlYmQtMjFlYS00ODdiLTg1ZjUtMzQ5NDA5N2VjODMzIiwicm9sZXMiOlsiRkVUQ0gtUk9MRVMtQlktQVBJIl0sInBlcm1pc3Npb25zIjpbIkZFVENILVBFUk1JU1NJT05TLUJZLUFQSSJdLCJhdWQiOiIzZDIzMzk0OS1hMmZiLTRhYjAtYjdlYy00NmY2MjU1YzUxMGUiLCJpc3MiOiJodHRwczovL2lkZW50aXR5Lm9jdG8uYWkiLCJpYXQiOjE3MTk2Nzg3NTl9.m3RpRr3vLoGekWhvk1fXHlTBAg1fkkO2V2eMfXddjLf30taFXnAOLoJIWHsGLupliLVW3JL9_wxPRhL2cGpDH_1_PeWDUYxKk_ZY1RjL9s_yoJf7fGeEy9-VPbmvjfYXcQTa_sxE99GeqwaODud26e_O04Q9n2KiNSwdeeion6ki9ctpIbDXZ3Wit_ltumGY0axDRInfm_QHwvo92r4W-3g8jN4lskS7ZA7CT5LCRq7GzFs5E2HsZq-59RnVhxnray6nG5fyG3U67Ff0ZCTuRaDY2DqRDOgQw1zRqTYMoW8zeOfozRxlGygdRcRU3AxnUOGOi7yijetkE9I60H9qlg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data dir here\n",
    "data_dir = \"../food_nutrition_data\"\n",
    "\n",
    "files = os.listdir(data_dir)\n",
    "file_texts = []\n",
    "for file in files:\n",
    "    with open(f\"{data_dir}/{file}\") as f:\n",
    "        file_text = f.read()\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=512, chunk_overlap=64, \n",
    "    )\n",
    "    texts = text_splitter.split_text(file_text)\n",
    "    for i, chunked_text in enumerate(texts):\n",
    "        file_texts.append(Document(page_content=chunked_text, \n",
    "                metadata={\"doc_title\": file.split(\".\")[0], \"chunk_num\": i}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(\n",
    "    file_texts,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model is not default parameter.\n",
      "                model was transferred to model_kwargs.\n",
      "                Please confirm that model is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.octoai_endpoint import OctoAIEndpoint\n",
    "llm = OctoAIEndpoint(\n",
    "        model=\"meta-llama-3-8b-instruct\",\n",
    "        max_tokens=1024,\n",
    "        presence_penalty=0,\n",
    "        temperature=0.1,\n",
    "        top_p=0.9,\n",
    "        octoai_api_token=OCTOAI_API_TOKEN\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template=\"\"\"You are a data analyst. You will be given unstructured data texts and figure out the schema. Return the schema. Be as general as possible so the schema can be used on most data input. Return the schema as PosgreSQL CREATE TABLE query. If possible, create multiple tables and relations between them when you see fit.\n",
    "Document: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "```sql\n",
      "CREATE TABLE documents (\n",
      "    id SERIAL PRIMARY KEY,\n",
      "    title VARCHAR(255) NOT NULL,\n",
      "    chunk_num INTEGER NOT NULL,\n",
      "    content TEXT NOT NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE nutrients (\n",
      "    id SERIAL PRIMARY KEY,\n",
      "    name VARCHAR(255) NOT NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE foods (\n",
      "    id SERIAL PRIMARY KEY,\n",
      "    name VARCHAR(255) NOT NULL,\n",
      "    description TEXT,\n",
      "    nutrient_id INTEGER,\n",
      "    FOREIGN KEY (nutrient_id) REFERENCES nutrients(id)\n",
      ");\n",
      "\n",
      "CREATE TABLE food_types (\n",
      "    id SERIAL PRIMARY KEY,\n",
      "    name VARCHAR(255) NOT NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE food_foods (\n",
      "    food_id INTEGER,\n",
      "    food_type_id INTEGER,\n",
      "    PRIMARY KEY (food_id, food_type_id),\n",
      "    FOREIGN KEY (food_id) REFERENCES foods(id),\n",
      "    FOREIGN KEY (food_type_id) REFERENCES food_types(id)\n",
      ");\n",
      "\n",
      "CREATE TABLE document_foods (\n",
      "    document_id INTEGER,\n",
      "    food_id INTEGER,\n",
      "    PRIMARY KEY (document_id, food_id),\n",
      "    FOREIGN KEY (document_id) REFERENCES documents(id),\n",
      "    FOREIGN KEY (food_id) REFERENCES foods(id)\n",
      ");\n",
      "\n",
      "CREATE TABLE document_nutrients (\n",
      "    document_id INTEGER,\n",
      "    nutrient_id INTEGER,\n",
      "    PRIMARY KEY (document_id, nutrient_id),\n",
      "    FOREIGN KEY (document_id) REFERENCES documents(id),\n",
      "    FOREIGN KEY (nutrient_id) REFERENCES nutrients(id)\n",
      ");\n",
      "```\n",
      "This schema captures the main entities and relationships in the data:\n",
      "\n",
      "* `documents`: represents individual documents with their titles, chunk numbers, and content.\n",
      "* `nutrients`: represents individual nutrients with their names.\n",
      "* `foods`: represents individual foods with their names, descriptions, and associated nutrients.\n",
      "* `food_types`: represents categories of foods (e.g., legumes, seeds, etc.).\n",
      "* `food_foods`: represents many-to-many relationships between foods and food types.\n",
      "* `document_foods`: represents many-to-many relationships between documents and foods.\n",
      "* `document_nutrients`: represents many-to-many relationships between documents and nutrients.\n",
      "\n",
      "This schema allows for flexible querying and analysis of the data, and can be extended or modified as needed to accommodate additional entities or relationships. Note that some relationships (e.g., between foods and nutrients) are many-to-many, while others (e.g., between documents and foods) are many-to-many. This is because a food can be associated with multiple nutrients, and a document can be associated with multiple foods. Similarly, a nutrient can be associated with multiple foods, and a food type can be associated with multiple foods. The schema is designed to accommodate these relationships and allow for efficient querying and analysis of the data.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"Show me the schema creation script\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcbs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
